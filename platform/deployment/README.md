# Install cnf and crd controller

The installation has been verified on kubernetes v1.23

Currently, the cnf and its dependencies can be utiltized in two mode: Push mode and Pull mode.

Push mode:
Configurations that generated by SDEWAN Central Controller will be directly pushed to hub/edge cluster using their kubeconfig which
they provided in the registration. CNF will get the configuration directly from the CR located in the cluster.

Pull Mode:
Configurations that generated by SDEWAN Central Controller will be pushed thru GitOps approach(first upload to public github). Extra
dependency tool Flux need to be installed on the cluster to pull the configuration back as local CR.


## Pre-condition
**1.Install cert-manager**

```
kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.6.1/cert-manager.yaml
```

**2.Label the node**

```
nodename=$(kubectl get node -o jsonpath='{.items[0].metadata.name}')
kubectl taint node $nodename node-role.kubernetes.io/master:NoSchedule-
kubectl label --overwrite node $nodename ovn4nfv-k8s-plugin=ovn-control-plane
```

**3.Install network**

For the network configuration, the helm charts of CNF and Controller need integrate Multus CNI with Calico as default network and icn-nodus. So you can refer to the [guide](https://github.com/akraino-edge-stack/icn-nodus/blob/master/doc/how-to-use.md#testing-with-cni-proxy) to setup your environment.

**4.Apply provide network**

- Create ovn-network and provider-network, e.g.
```
---
apiVersion: k8s.plugin.opnfv.org/v1alpha1
kind: ProviderNetwork
metadata:
  name: pnetwork
spec:
  cniType: ovn4nfv
  ipv4Subnets:
  - subnet: 10.10.70.1/24
    name: subnet
    gateway: 10.10.20.1/24
    excludeIps: 10.10.70.2 10.10.60.5..10.10.20.10
  providerNetType: VLAN
  vlan:
    logicalInterfaceName: eno1.100 // Change to your interface name
    providerInterfaceName: eno1
    vlanId: "100"
    vlanNodeSelector: all

---
apiVersion: k8s.plugin.opnfv.org/v1alpha1
kind: Network
metadata:
  name: ovn-network
spec:
  # Add fields here
  cniType: ovn4nfv
  ipv4Subnets:
  - subnet: 172.16.70.0/24
    name: subnet1
    gateway: 172.16.70.1/24
```
- Update `helm/sdewan_cnf/values.yaml` to configure the network information

**5.Install helm**

```
curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -
sudo apt-get install apt-transport-https --yes
echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm
```
**If you are deploying the CNF and CRD controller to use Pull mode, two extra steps are needed.**

**6.Prepare GitOps materials**
> Note: This is needed ONLY in Pull mode

While using Pull mode, following GitOps information need to get prepared(the one should match the information used in overlay controller)

- username: the username used for the github/gitlab account
- token: the personal access token used for github/gitlab. User can apply thru https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token
> Note: Token expiration time should be set less than 30 days. And scopes including repo, workflow, gist, project must be enabled for the access token
- repo: the repo name that the gitops configs will be uploaded to. e.g. "test-repo"
- clustername: the path where the gitops configs will be uploaded to. Please follow the format like this: akraino_scc_<overlay_name>+<device_name>

**7.Install Flux**
> Note: This is needed ONLY in Pull mode

```
brew install fluxcd/tap/flux
flux bootstrap github --owner=<username> --repository=<repo> --branch=<branch> --path=./clusters/<clustername> --personal
```
***Please fill in your Github username, the repo, branch and path you prepared before.***


## Steps to install CNF and CRD Controller

Please locate your directory to `./helm`.

**1.Create namespace for SDEWAN Central Controller v1Microservices**

```
kubectl create namespace sdewan-system
```

**2.Generate certificate for cnf**

```
kubectl apply -f cert/cnf_cert.yaml
```

**3.Install CNF**

```
helm package sdewan_cnf
helm install ./cnf-0.1.0.tgz --generate-name
```

**4.Install CRD controller**

```
helm package sdewan_controllers
helm install ./controllers-0.1.0.tgz --generate-name
```

## Pre-Configurations
> Note: Pre-configuration is ONLY needed in Push mode and in edge cluster which doesn't obtain a public IP address.

**1. Request and get the certificate from the central controller.**

**2. Apply the initial IPSec configuration. Here provides a sample of the configuration.**
```
cat > ipsec-proposal.yaml << EOF
apiVersion: batch.sdewan.akraino.org/v1alpha1
kind: IpsecProposal
metadata:
  labels:
    sdewanPurpose: base
    targetCluster: Device.edge-1
  name: proposal1
  namespace: default
spec:
  dh_group: modp4096
  encryption_algorithm: aes256
  hash_algorithm: sha256
EOF

kubectl apply -f ipsec-proposal.yaml
```

```
cat > ipsec-preconfig.yaml << EOF
apiVersion: batch.sdewan.akraino.org/v1alpha1
kind: IpsecHost
metadata:
  labels:
    sdewanPurpose: base
    targetCluster: Device.edge-1
  name: localedge1
  namespace: default
spec:
  authentication_method: pubkey
  connections:
    - conn_type: tunnel
      crypto_proposal:
        - proposal1
      local_sourceip: '%config'
      local_updown: /etc/updown_oip
      mark: ''
      mode: start
      name: ConnOverlay
  crypto_proposal:
    - proposal1
  force_crypto_proposal: '0'
  local_identifier: CN=device-edge-1-cert
  local_private_cert: <content-for-base64-encoded-private-key>
  local_public_cert: <content-for-base64-encoded-public-key>
  remote: <overlay-public-ip>
  remote_identifier: CN=sdewan-controller-base
  shared_ca: <content-for-base64-encoded-ca>
  type: policy-based
EOF

kubectl apply -f ipsec-preconfig.yaml
```
